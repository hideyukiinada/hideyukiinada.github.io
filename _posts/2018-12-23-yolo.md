---
layout: default
subject: ai
short_name: ai
title: Video sample of using YOLO to detect objects
---
# YOLO

YOLO is one of the popular methods to detect objects in an image.  Object detection means that the detector provides the coordinate of each object detected in a photo in addition to the label of each object.

Below photos show how YOLO identified my dogs' positions in each photo indicated by bounding boxes:

 <img src="/assets/images/maddie_and_olivia_yolo.jpg" width="400">

Maddie and Olivia

 <img src="/assets/images/aimee_yolo.jpg" width="400">

Aim√©e (the big puppy ;-)

I created a [a short video clip](https://www.youtube.com/watch?v=GToRQ4Tiqrs) to demo how YOLO processes traffic on a city street.
I took a video of Taylor St in downtown San Jose and ran it through YOLO to mark objects' location.

 ![video](https://img.youtube.com/vi/GToRQ4Tiqrs/0.jpg)

Here are the steps that you want to follow if you want to do this yourself:

1. Prepare a video
    1. Capture a video or find a video you want to use for object detection.
    1. Extract frames from the video (e.g. using ffmpeg)
1. Go to [the YOLO developer's main website](https://pjreddie.com/darknet/yolo/). Follow instructions on the website has instructions:
    1. git clone the source code 
    1. Download pre-trained weights file
    1. Build using make
    1. Run an example program
1. Go to [pyimagesearch.com](https://www.pyimagesearch.com/2018/11/12/yolo-object-detection-with-opencv/) and download the example Python code to use YOLO with [OpenCV's neural network module](https://docs.opencv.org/3.4/d6/d0f/group__dnn.html).  The site has detailed instructions for the example.
    1. Copy three files from your local YOLO installation to a directory under the example code
        1. coco.names
        1. yolov3.weights
        1. yolov3.cfg
    1. Make sure that the example code works.
    1. Tweak the code to read video frame files and output frame files.
    1. Run the script
1. Combine frames to a video (e.g. using ffmpeg again)


